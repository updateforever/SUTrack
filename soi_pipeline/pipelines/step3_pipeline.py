# # pytracking/soi_pipeline/pipelines/step3_pipeline.py
# import os
# import json
# from tqdm import tqdm
# from ..core.data_processor import DataProcessor
# from ..core.frame_extractor import FrameExtractor


# def run_step3_box_filtering(config, dataset) -> str:
#     """è¿è¡ŒStep 3.1: è¾¹ç•Œæ¡†è¿‡æ»¤å’Œåˆå¹¶ï¼ˆæŒ‰åºåˆ—è·³è¿‡ï¼‰"""
#     print("ğŸ”„ Starting Step 3.1: Box filtering and merging")
    
#     output_dir = os.path.join(config.output_dir, "step3_1_filtered_boxes")
#     os.makedirs(output_dir, exist_ok=True)
    
#     processor = DataProcessor(config)
    
#     for seq in tqdm(dataset, desc="Processing sequences"):
#         seq_name = seq.name
#         output_path = os.path.join(output_dir, f"{seq_name}.jsonl")

#         if config.skip_existing_results and os.path.exists(output_path):
#             if config.verbose:
#                 print(f"â© Skipped {seq_name}: already exists.")
#             continue
        
#         try:
#             filtered_boxes = processor.process_sequence(seq_name, seq.dataset, seq.ground_truth_rect)
#             with open(output_path, 'w', encoding='utf-8') as f:
#                 for frame_boxes in filtered_boxes:
#                     f.write(json.dumps(frame_boxes, ensure_ascii=False) + '\n')
#             if config.verbose:
#                 print(f"âœ… {seq_name}: processed {len(filtered_boxes)} frames")
#         except Exception as e:
#             print(f"âŒ Failed to process {seq_name}: {e}")
#             continue
    
#     print(f"âœ… Step 3.1 completed. Results saved to {output_dir}")
#     return output_dir


# def run_step3_frame_extraction(config, dataset, step3_1_dir: str) -> str:
#     """è¿è¡ŒStep 3.2: SOIå¸§æå–ï¼ˆæŒ‰åºåˆ—è·³è¿‡ï¼‰"""
#     print("ğŸ”„ Starting Step 3.2: SOI frame extraction")
    
#     output_dir = os.path.join(config.output_dir, "step3_2_soi_frames")
#     os.makedirs(output_dir, exist_ok=True)
    
#     extractor = FrameExtractor(config)
    
#     for seq in tqdm(dataset, desc="Extracting SOI frames"):
#         seq_name = seq.name
#         step3_1_jsonl = os.path.join(step3_1_dir, f"{seq_name}.jsonl")
#         output_path = os.path.join(output_dir, f"{seq_name}_soi_frames.jsonl")

#         # è·³è¿‡å·²å®Œæˆåºåˆ—
#         if config.skip_existing_results and os.path.exists(output_path):
#             if config.verbose:
#                 print(f"â© Skipped {seq_name}: already exists.")
#             continue
        
#         if not os.path.exists(step3_1_jsonl):
#             if config.verbose:
#                 print(f"âš ï¸ Warning: No filtered boxes found for {seq_name}")
#             continue

#         try:
#             soi_frames = extractor.extract_soi_frames(
#                 seq_name=seq_name,
#                 dataset_name=seq.dataset,
#                 frames=seq.frames,
#                 ground_truth_rects=seq.ground_truth_rect,
#                 step3_1_jsonl=step3_1_jsonl
#             )
#             with open(output_path, 'w', encoding='utf-8') as f:
#                 json.dump(soi_frames, f, ensure_ascii=False)
#             if config.verbose:
#                 print(f"âœ… {seq_name}: extracted {len(soi_frames)} SOI frames")
#         except Exception as e:
#             print(f"âŒ Failed to extract SOI frames for {seq_name}: {e}")
#             continue
    
#     print(f"âœ… Step 3.2 completed. Results saved to {output_dir}")
#     return output_dir


# pytracking/soi_pipeline/pipelines/step3_pipeline.py
import os
import json
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
from collections import defaultdict, Counter
from tqdm import tqdm
from ..core.data_processor import DataProcessor
from ..core.frame_extractor import FrameExtractor


class Step3Statistics:
    """Step3ç»Ÿè®¡å’Œå¯è§†åŒ–ç±»"""
    
    def __init__(self):
        self.reset()
    
    def reset(self):
        """é‡ç½®ç»Ÿè®¡æ•°æ®"""
        # Step 3.1 ç»Ÿè®¡
        self.box_stats = {
            'soi_boxes_per_frame': [],
            'det_boxes_per_frame': [],
            'total_boxes_per_frame': [],
            'filtered_boxes_per_frame': [],
            'sequences': []
        }
        
        # Step 3.2 ç»Ÿè®¡
        self.frame_stats = {
            'candidates_per_seq': [],
            'final_frames_per_seq': [],
            'filter_reasons': defaultdict(int),
            'sequences': []
        }
    
    def add_box_stats(self, seq_name: str, soi_counts: list, det_counts: list, 
                     total_counts: list, filtered_counts: list):
        """æ·»åŠ æ¡†ç»Ÿè®¡æ•°æ®"""
        self.box_stats['sequences'].append(seq_name)
        self.box_stats['soi_boxes_per_frame'].extend(soi_counts)
        self.box_stats['det_boxes_per_frame'].extend(det_counts)
        self.box_stats['total_boxes_per_frame'].extend(total_counts)
        self.box_stats['filtered_boxes_per_frame'].extend(filtered_counts)
    
    def add_frame_stats(self, seq_name: str, candidates_count: int, final_count: int, 
                       filter_reasons: dict):
        """æ·»åŠ å¸§ç»Ÿè®¡æ•°æ®"""
        self.frame_stats['sequences'].append(seq_name)
        self.frame_stats['candidates_per_seq'].append(candidates_count)
        self.frame_stats['final_frames_per_seq'].append(final_count)
        
        for reason, count in filter_reasons.items():
            self.frame_stats['filter_reasons'][reason] += count
    
    def plot_box_statistics(self, output_dir: str):
        """ç»˜åˆ¶æ¡†ç»Ÿè®¡å›¾è¡¨"""
        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        fig.suptitle('Step 3.1: Box Filtering Statistics', fontsize=16)
        
        # 1. SOIæ¡†æ•°é‡åˆ†å¸ƒ
        axes[0, 0].hist(self.box_stats['soi_boxes_per_frame'], bins=50, alpha=0.7, color='blue')
        axes[0, 0].set_title('SOI Boxes per Frame Distribution')
        axes[0, 0].set_xlabel('Number of SOI Boxes')
        axes[0, 0].set_ylabel('Frequency')
        axes[0, 0].axvline(np.mean(self.box_stats['soi_boxes_per_frame']), 
                          color='red', linestyle='--', 
                          label=f'Mean: {np.mean(self.box_stats["soi_boxes_per_frame"]):.2f}')
        axes[0, 0].legend()
        
        # 2. æ£€æµ‹æ¡†æ•°é‡åˆ†å¸ƒ
        axes[0, 1].hist(self.box_stats['det_boxes_per_frame'], bins=50, alpha=0.7, color='green')
        axes[0, 1].set_title('Detection Boxes per Frame Distribution') 
        axes[0, 1].set_xlabel('Number of Detection Boxes')
        axes[0, 1].set_ylabel('Frequency')
        axes[0, 1].axvline(np.mean(self.box_stats['det_boxes_per_frame']), 
                          color='red', linestyle='--',
                          label=f'Mean: {np.mean(self.box_stats["det_boxes_per_frame"]):.2f}')
        axes[0, 1].legend()
        
        # 3. è¿‡æ»¤å‰åå¯¹æ¯”
        x = range(len(self.box_stats['total_boxes_per_frame']))
        axes[1, 0].scatter(x[::100], [self.box_stats['total_boxes_per_frame'][i] for i in x[::100]], 
                          alpha=0.6, s=10, label='Before Filtering', color='orange')
        axes[1, 0].scatter(x[::100], [self.box_stats['filtered_boxes_per_frame'][i] for i in x[::100]], 
                          alpha=0.6, s=10, label='After Filtering', color='purple')
        axes[1, 0].set_title('Boxes Before vs After Filtering (Sampled)')
        axes[1, 0].set_xlabel('Frame Index (Sampled)')
        axes[1, 0].set_ylabel('Number of Boxes')
        axes[1, 0].legend()
        
        # 4. è¿‡æ»¤æ•ˆæœç»Ÿè®¡
        total_before = sum(self.box_stats['total_boxes_per_frame'])
        total_after = sum(self.box_stats['filtered_boxes_per_frame'])
        filter_ratio = (total_before - total_after) / total_before if total_before > 0 else 0
        
        categories = ['Original', 'Filtered']
        values = [total_before, total_after]
        colors = ['lightcoral', 'lightblue']
        
        bars = axes[1, 1].bar(categories, values, color=colors)
        axes[1, 1].set_title(f'Total Boxes: Filtering Effect\n(Filtered Ratio: {filter_ratio:.2%})')
        axes[1, 1].set_ylabel('Total Number of Boxes')
        
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for bar, value in zip(bars, values):
            axes[1, 1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + max(values)*0.01,
                           f'{value:,}', ha='center', va='bottom')
        
        plt.tight_layout()
        plt.savefig(os.path.join(output_dir, 'step3_1_box_statistics.png'), dpi=300, bbox_inches='tight')
        plt.close()
        
        # ç”Ÿæˆç»Ÿè®¡æŠ¥å‘Š
        self._generate_box_report(output_dir)
    
    def plot_frame_statistics(self, output_dir: str):
        """ç»˜åˆ¶å¸§ç»Ÿè®¡å›¾è¡¨"""
        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        fig.suptitle('Step 3.2: SOI Frame Extraction Statistics', fontsize=16)
        
        # 1. å€™é€‰å¸§æ•°é‡åˆ†å¸ƒ
        axes[0, 0].hist(self.frame_stats['candidates_per_seq'], bins=30, alpha=0.7, color='orange')
        axes[0, 0].set_title('Candidate Frames per Sequence')
        axes[0, 0].set_xlabel('Number of Candidate Frames')
        axes[0, 0].set_ylabel('Number of Sequences')
        axes[0, 0].axvline(np.mean(self.frame_stats['candidates_per_seq']), 
                          color='red', linestyle='--',
                          label=f'Mean: {np.mean(self.frame_stats["candidates_per_seq"]):.1f}')
        axes[0, 0].legend()
        
        # 2. æœ€ç»ˆå¸§æ•°é‡åˆ†å¸ƒ
        axes[0, 1].hist(self.frame_stats['final_frames_per_seq'], bins=30, alpha=0.7, color='green')
        axes[0, 1].set_title('Final SOI Frames per Sequence')
        axes[0, 1].set_xlabel('Number of Final Frames')
        axes[0, 1].set_ylabel('Number of Sequences')
        axes[0, 1].axvline(np.mean(self.frame_stats['final_frames_per_seq']), 
                          color='red', linestyle='--',
                          label=f'Mean: {np.mean(self.frame_stats["final_frames_per_seq"]):.1f}')
        axes[0, 1].legend()
        
        # 3. å€™é€‰å¸§vsæœ€ç»ˆå¸§å¯¹æ¯”
        axes[1, 0].scatter(self.frame_stats['candidates_per_seq'], 
                          self.frame_stats['final_frames_per_seq'], alpha=0.6)
        axes[1, 0].plot([0, max(self.frame_stats['candidates_per_seq'])], 
                       [0, max(self.frame_stats['candidates_per_seq'])], 
                       'r--', alpha=0.5, label='y=x')
        axes[1, 0].set_title('Candidate vs Final Frames per Sequence')
        axes[1, 0].set_xlabel('Candidate Frames')
        axes[1, 0].set_ylabel('Final Frames')
        axes[1, 0].legend()
        
        # 4. è¿‡æ»¤åŸå› åˆ†å¸ƒ
        if self.frame_stats['filter_reasons']:
            reasons = list(self.frame_stats['filter_reasons'].keys())
            counts = list(self.frame_stats['filter_reasons'].values())
            
            # åˆ›å»ºé¥¼å›¾
            wedges, texts, autotexts = axes[1, 1].pie(counts, labels=reasons, autopct='%1.1f%%')
            axes[1, 1].set_title('Frame Filtering Reasons Distribution')
            
            # ç¾åŒ–é¥¼å›¾æ–‡å­—
            for autotext in autotexts:
                autotext.set_color('white')
                autotext.set_fontweight('bold')
        else:
            axes[1, 1].text(0.5, 0.5, 'No filtering reasons data', 
                           ha='center', va='center', transform=axes[1, 1].transAxes)
            axes[1, 1].set_title('Frame Filtering Reasons Distribution')
        
        plt.tight_layout()
        plt.savefig(os.path.join(output_dir, 'step3_2_frame_statistics.png'), dpi=300, bbox_inches='tight')
        plt.close()
        
        # ç”Ÿæˆç»Ÿè®¡æŠ¥å‘Š
        self._generate_frame_report(output_dir)
    
    def _generate_box_report(self, output_dir: str):
        """ç”Ÿæˆæ¡†ç»Ÿè®¡æŠ¥å‘Š"""
        report_path = os.path.join(output_dir, 'step3_1_box_report.txt')
        
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write("=== Step 3.1: Box Filtering Statistics Report ===\n\n")
            
            # åŸºæœ¬ç»Ÿè®¡
            f.write("ğŸ“Š Basic Statistics:\n")
            f.write(f"Total frames processed: {len(self.box_stats['soi_boxes_per_frame'])}\n")
            f.write(f"Total sequences: {len(set(self.box_stats['sequences']))}\n\n")
            
            # SOIæ¡†ç»Ÿè®¡
            soi_boxes = self.box_stats['soi_boxes_per_frame']
            f.write("ğŸ¯ SOI Boxes Statistics:\n")
            f.write(f"Mean SOI boxes per frame: {np.mean(soi_boxes):.2f}\n")
            f.write(f"Std SOI boxes per frame: {np.std(soi_boxes):.2f}\n")
            f.write(f"Max SOI boxes in single frame: {max(soi_boxes)}\n")
            f.write(f"Frames with 0 SOI boxes: {soi_boxes.count(0)} ({soi_boxes.count(0)/len(soi_boxes)*100:.1f}%)\n\n")
            
            # æ£€æµ‹æ¡†ç»Ÿè®¡
            det_boxes = self.box_stats['det_boxes_per_frame']
            f.write("ğŸ” Detection Boxes Statistics:\n")
            f.write(f"Mean detection boxes per frame: {np.mean(det_boxes):.2f}\n")
            f.write(f"Std detection boxes per frame: {np.std(det_boxes):.2f}\n")
            f.write(f"Max detection boxes in single frame: {max(det_boxes)}\n")
            f.write(f"Frames with 0 detection boxes: {det_boxes.count(0)} ({det_boxes.count(0)/len(det_boxes)*100:.1f}%)\n\n")
            
            # è¿‡æ»¤æ•ˆæœ
            total_before = sum(self.box_stats['total_boxes_per_frame'])
            total_after = sum(self.box_stats['filtered_boxes_per_frame'])
            f.write("âœ‚ï¸ Filtering Effect:\n")
            f.write(f"Total boxes before filtering: {total_before:,}\n")
            f.write(f"Total boxes after filtering: {total_after:,}\n")
            f.write(f"Boxes filtered out: {total_before - total_after:,}\n")
            f.write(f"Filtering ratio: {(total_before - total_after)/total_before*100:.2f}%\n")
    
    def _generate_frame_report(self, output_dir: str):
        """ç”Ÿæˆå¸§ç»Ÿè®¡æŠ¥å‘Š"""
        report_path = os.path.join(output_dir, 'step3_2_frame_report.txt')
        
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write("=== Step 3.2: SOI Frame Extraction Statistics Report ===\n\n")
            
            # åŸºæœ¬ç»Ÿè®¡
            f.write("ğŸ“Š Basic Statistics:\n")
            f.write(f"Total sequences processed: {len(self.frame_stats['sequences'])}\n")
            f.write(f"Total candidate frames: {sum(self.frame_stats['candidates_per_seq'])}\n")
            f.write(f"Total final SOI frames: {sum(self.frame_stats['final_frames_per_seq'])}\n\n")
            
            # åºåˆ—çº§ç»Ÿè®¡
            candidates = self.frame_stats['candidates_per_seq']
            final_frames = self.frame_stats['final_frames_per_seq']
            
            f.write("ğŸ¯ Per-Sequence Statistics:\n")
            f.write(f"Mean candidate frames per sequence: {np.mean(candidates):.1f}\n")
            f.write(f"Mean final frames per sequence: {np.mean(final_frames):.1f}\n")
            f.write(f"Sequences with 0 candidates: {candidates.count(0)}\n")
            f.write(f"Sequences with 0 final frames: {final_frames.count(0)}\n\n")
            
            # è¿‡æ»¤æ•ˆæœ
            total_candidates = sum(candidates)
            total_final = sum(final_frames)
            if total_candidates > 0:
                retention_rate = total_final / total_candidates
                f.write("âœ‚ï¸ Filtering Effect:\n")
                f.write(f"Frame retention rate: {retention_rate*100:.2f}%\n")
                f.write(f"Frames filtered out: {total_candidates - total_final}\n\n")
            
            # è¿‡æ»¤åŸå› 
            if self.frame_stats['filter_reasons']:
                f.write("ğŸ” Filtering Reasons:\n")
                total_filtered = sum(self.frame_stats['filter_reasons'].values())
                for reason, count in sorted(self.frame_stats['filter_reasons'].items(), 
                                           key=lambda x: x[1], reverse=True):
                    f.write(f"{reason}: {count} ({count/total_filtered*100:.1f}%)\n")


def run_step3_box_filtering(config, dataset) -> str:
    """è¿è¡ŒStep 3.1: è¾¹ç•Œæ¡†è¿‡æ»¤å’Œåˆå¹¶(æŒ‰åºåˆ—è·³è¿‡) - å¢å¼ºç‰ˆwithç»Ÿè®¡"""
    print("ğŸ”„ Starting Step 3.1: Box filtering and merging (with statistics)")
    
    output_dir = os.path.join(config.output_dir, "step3_1_filtered_boxes")
    os.makedirs(output_dir, exist_ok=True)
    
    processor = DataProcessor(config)
    stats = Step3Statistics()
    
    for seq in tqdm(dataset, desc="Processing sequences"):
        seq_name = seq.name
        output_path = os.path.join(output_dir, f"{seq_name}.jsonl")

        if config.skip_existing_results and os.path.exists(output_path):
            if config.verbose:
                print(f"â© Skipped {seq_name}: already exists.")
            continue
        
        try:
            # æ”¶é›†ç»Ÿè®¡æ•°æ®
            soi_counts = []
            det_counts = []
            total_counts = []
            filtered_counts = []
            
            for frame_idx in range(len(seq.ground_truth_rect)):
                # æ”¶é›†åŸå§‹æ¡†æ•°é‡
                soi_boxes = processor.collect_soi_boxes(seq_name, frame_idx)
                det_boxes = processor.collect_detection_boxes(seq_name, frame_idx)
                
                soi_count = len(soi_boxes)
                det_count = len(det_boxes)
                total_count = soi_count + det_count
                
                soi_counts.append(soi_count)
                det_counts.append(det_count)
                total_counts.append(total_count)
            
            # æ‰§è¡Œå¤„ç†
            filtered_boxes = processor.process_sequence(seq_name, seq.dataset, seq.ground_truth_rect)
            
            # æ”¶é›†è¿‡æ»¤åçš„æ¡†æ•°é‡
            for frame_boxes in filtered_boxes:
                filtered_counts.append(len(frame_boxes) - 1)  # å‡å»GTæ¡†
            
            # æ·»åŠ ç»Ÿè®¡æ•°æ®
            stats.add_box_stats(seq_name, soi_counts, det_counts, total_counts, filtered_counts)
            
            # ä¿å­˜ç»“æœ
            with open(output_path, 'w', encoding='utf-8') as f:
                for frame_boxes in filtered_boxes:
                    f.write(json.dumps(frame_boxes, ensure_ascii=False) + '\n')
            
            if config.verbose:
                avg_soi = np.mean(soi_counts)
                avg_det = np.mean(det_counts)
                avg_filtered = np.mean(filtered_counts)
                print(f"âœ… {seq_name}: {len(filtered_boxes)} frames, "
                      f"avg SOI: {avg_soi:.1f}, avg DET: {avg_det:.1f}, avg filtered: {avg_filtered:.1f}")
                
        except Exception as e:
            print(f"âŒ Failed to process {seq_name}: {e}")
            continue
    
    # ç”Ÿæˆç»Ÿè®¡å›¾è¡¨å’ŒæŠ¥å‘Š
    if hasattr(config, 'generate_statistics') and config.generate_statistics:
        print("ğŸ“Š Generating statistics...")
        stats.plot_box_statistics(output_dir)
        print(f"ğŸ“ˆ Statistics saved to {output_dir}")
    
    print(f"âœ… Step 3.1 completed. Results saved to {output_dir}")
    return output_dir


def run_step3_frame_extraction(config, dataset, step3_1_dir: str) -> str:
    """è¿è¡ŒStep 3.2: SOIå¸§æå–(æŒ‰åºåˆ—è·³è¿‡) - å¢å¼ºç‰ˆwithç»Ÿè®¡"""
    print("ğŸ”„ Starting Step 3.2: SOI frame extraction (with statistics)")
    
    output_dir = os.path.join(config.output_dir, "step3_2_soi_frames")
    os.makedirs(output_dir, exist_ok=True)
    
    extractor = FrameExtractor(config)
    stats = Step3Statistics()
    
    for seq in tqdm(dataset, desc="Extracting SOI frames"):
        seq_name = seq.name
        step3_1_jsonl = os.path.join(step3_1_dir, f"{seq_name}.jsonl")
        output_path = os.path.join(output_dir, f"{seq_name}_soi_frames.jsonl")

        # è·³è¿‡å·²å®Œæˆåºåˆ—
        if config.skip_existing_results and os.path.exists(output_path):
            if config.verbose:
                print(f"â© Skipped {seq_name}: already exists.")
            continue
        
        if not os.path.exists(step3_1_jsonl):
            if config.verbose:
                print(f"âš ï¸ Warning: No filtered boxes found for {seq_name}")
            continue

        try:
            # å…ˆè·å–å€™é€‰å¸§ï¼ˆç”¨äºç»Ÿè®¡ï¼‰
            trackers = extractor.load_tracker_status(seq_name, seq.dataset)
            if not trackers:
                continue
                
            candidates = extractor.extract_soi_candidates(trackers, len(seq.frames), seq.ground_truth_rect)
            
            # æå–æœ€ç»ˆSOIå¸§ï¼ˆåŒ…å«è¯¦ç»†è¿‡æ»¤ç»Ÿè®¡ï¼‰
            soi_frames = extractor.extract_soi_frames(
                seq_name=seq_name,
                dataset_name=seq.dataset,
                frames=seq.frames,
                ground_truth_rects=seq.ground_truth_rect,
                step3_1_jsonl=step3_1_jsonl
            )
            
            # è®¡ç®—è¿‡æ»¤åŸå› ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼Œå®é™…å¯ä»¥åœ¨extractorä¸­è¯¦ç»†è¿½è¸ªï¼‰
            filter_reasons = {}
            filtered_count = len(candidates) - len(soi_frames)
            if filtered_count > 0:
                # è¿™é‡Œå¯ä»¥æ·»åŠ æ›´è¯¦ç»†çš„è¿‡æ»¤åŸå› ç»Ÿè®¡
                filter_reasons['quality_or_gap_filter'] = filtered_count
            
            # æ·»åŠ ç»Ÿè®¡æ•°æ®
            stats.add_frame_stats(seq_name, len(candidates), len(soi_frames), filter_reasons)
            
            # ä¿å­˜ç»“æœ
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(soi_frames, f, ensure_ascii=False)
            
            if config.verbose:
                print(f"âœ… {seq_name}: {len(candidates)} candidates â†’ {len(soi_frames)} final SOI frames")
                
        except Exception as e:
            print(f"âŒ Failed to extract SOI frames for {seq_name}: {e}")
            continue
    
    # ç”Ÿæˆç»Ÿè®¡å›¾è¡¨å’ŒæŠ¥å‘Š
    if hasattr(config, 'generate_statistics') and config.generate_statistics:
        print("ğŸ“Š Generating statistics...")
        stats.plot_frame_statistics(output_dir)
        print(f"ğŸ“ˆ Statistics saved to {output_dir}")
    
    print(f"âœ… Step 3.2 completed. Results saved to {output_dir}")
    return output_dir